{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertForSequenceClassification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "229baabeed0f4b07ae42485d4ba646d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01763724238c457bad00b0cae5f2b6b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4861bc0646ce4b97819ef9ff9456e7c1",
              "IPY_MODEL_eeae77e8301545348d9eaad6ab9e88da"
            ]
          }
        },
        "048bb8e8da044654a6efbf3f83f1ada9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9970995733c4c36a55f4d090e31d393",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b38436bf09a64ad980baa81791fcd70a",
              "IPY_MODEL_b7e36d7b23b84ca0b8a8f8df165b9d1e"
            ]
          }
        },
        "c9970995733c4c36a55f4d090e31d393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b38436bf09a64ad980baa81791fcd70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbe665a6b889456db5abe8971557cfac",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87d9626c496d4fbea05e008707af8cfb"
          }
        },
        "b7e36d7b23b84ca0b8a8f8df165b9d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1024a366fca6423f890741c7bd26c612",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 4.63kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77b411bb8eaa4f12bf541df95aa7907a"
          }
        },
        "fbe665a6b889456db5abe8971557cfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87d9626c496d4fbea05e008707af8cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1024a366fca6423f890741c7bd26c612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77b411bb8eaa4f12bf541df95aa7907a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5021e91405048beb2a13a876efadcd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ea8d6ca307b4657b8c47ad40fa4e58b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_032c493f46224096b9156e4e6999a5ed",
              "IPY_MODEL_00736e59566d43078d56f168295fc9b7"
            ]
          }
        },
        "4ea8d6ca307b4657b8c47ad40fa4e58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "032c493f46224096b9156e4e6999a5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_717091da54264b7b9487528926aaa74c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef8ff1a7f6bc4237928917f23eb82016"
          }
        },
        "00736e59566d43078d56f168295fc9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91da11e9280047c6b6730150d046479a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:37&lt;00:00, 11.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68cad836cae24f6fa66fe5c4b684b4b6"
          }
        },
        "717091da54264b7b9487528926aaa74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef8ff1a7f6bc4237928917f23eb82016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91da11e9280047c6b6730150d046479a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68cad836cae24f6fa66fe5c4b684b4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzwbXICXugOP",
        "colab_type": "code",
        "outputId": "dfe28f26-b0cb-432f-d1dd-829d7db16288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjLiNwBovFHS",
        "colab_type": "code",
        "outputId": "8dfcf59d-5cc1-46e4-8572-0f09a7fb6443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 7.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 22.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 26.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=58d9d33e2f33ef176081fd7013180b240a0f97804e5ecf29eff5bc23ce3e2fdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHMr1ArNvMFK",
        "colab_type": "code",
        "outputId": "fb0cbebd-d962-4703-9fb4-a7f5e0ce4dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "229baabeed0f4b07ae42485d4ba646d6"
          ]
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from IPython.display import clear_output\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n",
        "\n",
        "# 取得此預訓練模型所使用的 tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "\n",
        "clear_output()\n",
        "print(\"PyTorch 版本：\", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 版本： 1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fPHzjewvO_I",
        "colab_type": "code",
        "outputId": "10181d1c-2fea-4391-e7b1-9514b2c64c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = tokenizer.vocab\n",
        "print(\"字典大小：\", len(vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "字典大小： 21128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdipWKKpvTDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_file=\"/content/drive/My Drive/colab/bert/dataset/train.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_file)\n",
        "empty_title = ((df_train['title2_zh'].isnull()) \\\n",
        "               | (df_train['title1_zh'].isnull()) \\\n",
        "               | (df_train['title2_zh'] == '') \\\n",
        "               | (df_train['title2_zh'] == '0'))\n",
        "df_train = df_train[~empty_title]\n",
        "\n",
        "# 剔除過長的樣本以避免 BERT 無法將整個輸入序列放入記憶體不多的 GPU\n",
        "MAX_LENGTH = 30\n",
        "df_train = df_train[~(df_train.title1_zh.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "df_train = df_train[~(df_train.title2_zh.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "\n",
        "# 只用 1% 訓練數據看看 BERT 對少量標註數據有多少幫助\n",
        "SAMPLE_FRAC = 0.01\n",
        "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9527)\n",
        "\n",
        "# 去除不必要的欄位並重新命名兩標題的欄位名\n",
        "df_train = df_train.reset_index()\n",
        "df_train = df_train.loc[:, ['title1_zh', 'title2_zh', 'label']]\n",
        "df_train.columns = ['text_a', 'text_b', 'label']\n",
        "\n",
        "# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n",
        "df_train.to_csv(\"/content/drive/My Drive/colab/bert/dataset/train.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"訓練樣本數：\", len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOq_2-C-v9UJ",
        "colab_type": "code",
        "outputId": "ae0d5931-389d-4ae2-de72-40950b9670c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "df_train.label.value_counts() / len(df_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "unrelated    0.679338\n",
              "agreed       0.294317\n",
              "disagreed    0.026346\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVIAMEAKv_uy",
        "colab_type": "code",
        "outputId": "554c50e6-2380-4aed-9e62-15785e19ffcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "test_file=\"/content/drive/My Drive/colab/bert/dataset/test.csv\"\n",
        "df_test = pd.read_csv(test_file)\n",
        "df_test = df_test.loc[:, [\"title1_zh\", \"title2_zh\", \"id\"]]\n",
        "df_test.columns = [\"text_a\", \"text_b\", \"Id\"]\n",
        "df_test.to_csv(\"/content/drive/My Drive/colab/bert/dataset/test.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"預測樣本數：\", len(df_test))\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "預測樣本數： 80126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
              "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
              "      <td>321187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
              "      <td>321190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>321189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
              "      <td>321193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
              "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
              "      <td>321191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text_a                       text_b      Id\n",
              "0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？  321187\n",
              "1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国  321190\n",
              "2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思  321189\n",
              "3              萨达姆被捕后告诫美国的一句话，发人深思  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！  321193\n",
              "4              萨达姆被捕后告诫美国的一句话，发人深思         中国川贝枇杷膏在美国受到热捧？纯属谣言！  321191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G95-szgwJUL",
        "colab_type": "code",
        "outputId": "828c83bd-5e38-450e-efbd-78e94556795d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ratio = len(df_test) / len(df_train)\n",
        "print(\"測試集樣本數 / 訓練集樣本數 = {:.1f} 倍\".format(ratio))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "測試集樣本數 / 訓練集樣本數 = 30.2 倍\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruVwgyBhwMAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。\n",
        "此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n",
        "- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n",
        "- segments_tensor：可以用來識別兩個句子界限的 binary tensor\n",
        "- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n",
        "\"\"\"\n",
        "from torch.utils.data import Dataset\n",
        " \n",
        "    \n",
        "class FakeNewsDataset(Dataset):\n",
        "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
        "    def __init__(self, mode, tokenizer):\n",
        "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
        "        self.mode = mode\n",
        "        # 大數據你會需要用 iterator=True\n",
        "        self.df = pd.read_csv(\"/content/drive/My Drive/colab/bert/dataset/\"+mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
        "        self.len = len(self.df)\n",
        "        self.label_map = {'agreed': 0, 'disagreed': 1, 'unrelated': 2}\n",
        "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
        "    \n",
        "    # 定義回傳一筆訓練 / 測試數據的函式\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            text_a, text_b = self.df.iloc[idx, :2].values\n",
        "            label_tensor = None\n",
        "        else:\n",
        "            text_a, text_b, label = self.df.iloc[idx, :].values\n",
        "            # 將 label 文字也轉換成索引方便轉換成 tensor\n",
        "            label_id = self.label_map[label]\n",
        "            label_tensor = torch.tensor(label_id)\n",
        "            \n",
        "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens_a = self.tokenizer.tokenize(text_a)\n",
        "        word_pieces += tokens_a + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        # 第二個句子的 BERT tokens\n",
        "        tokens_b = self.tokenizer.tokenize(text_b)\n",
        "        word_pieces += tokens_b + [\"[SEP]\"]\n",
        "        len_b = len(word_pieces) - len_a\n",
        "        \n",
        "        # 將整個 token 序列轉換成索引序列\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "        tokens_tensor = torch.tensor(ids)\n",
        "        \n",
        "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
        "        segments_tensor = torch.tensor([0] * len_a + [1] * len_b, \n",
        "                                        dtype=torch.long)\n",
        "        \n",
        "        return (tokens_tensor, segments_tensor, label_tensor)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    \n",
        "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
        "trainset = FakeNewsDataset(\"train\", tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT2IDOowwQpa",
        "colab_type": "code",
        "outputId": "972e15fd-c2cd-4d86-8b7c-d5688b28bad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "# 選擇第一個樣本\n",
        "sample_idx = 0\n",
        "\n",
        "# 將原始文本拿出做比較\n",
        "text_a, text_b, label = trainset.df.iloc[sample_idx].values\n",
        "\n",
        "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
        "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
        "\n",
        "# 將 tokens_tensor 還原成文本\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
        "combined_text = \"\".join(tokens)\n",
        "\n",
        "# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
        "print(f\"\"\"[原始文本]\n",
        "句子 1：{text_a}\n",
        "句子 2：{text_b}\n",
        "分類  ：{label}\n",
        "\n",
        "--------------------\n",
        "\n",
        "[Dataset 回傳的 tensors]\n",
        "tokens_tensor  ：{tokens_tensor}\n",
        "\n",
        "segments_tensor：{segments_tensor}\n",
        "\n",
        "label_tensor   ：{label_tensor}\n",
        "\n",
        "--------------------\n",
        "\n",
        "[還原 tokens_tensors]\n",
        "{combined_text}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[原始文本]\n",
            "句子 1：苏有朋要结婚了，但网友觉得他还是和林心如比较合适\n",
            "句子 2：好闺蜜结婚给不婚族的秦岚扔花球，倒霉的秦岚掉水里笑哭苏有朋！\n",
            "分類  ：unrelated\n",
            "\n",
            "--------------------\n",
            "\n",
            "[Dataset 回傳的 tensors]\n",
            "tokens_tensor  ：tensor([ 101, 5722, 3300, 3301, 6206, 5310, 2042,  749, 8024,  852, 5381, 1351,\n",
            "        6230, 2533,  800, 6820, 3221, 1469, 3360, 2552, 1963, 3683, 6772, 1394,\n",
            "        6844,  102, 1962, 7318, 6057, 5310, 2042, 5314,  679, 2042, 3184, 4638,\n",
            "        4912, 2269, 2803, 5709, 4413, 8024,  948, 7450, 4638, 4912, 2269, 2957,\n",
            "        3717, 7027, 5010, 1526, 5722, 3300, 3301, 8013,  102])\n",
            "\n",
            "segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "label_tensor   ：2\n",
            "\n",
            "--------------------\n",
            "\n",
            "[還原 tokens_tensors]\n",
            "[CLS]苏有朋要结婚了，但网友觉得他还是和林心如比较合适[SEP]好闺蜜结婚给不婚族的秦岚扔花球，倒霉的秦岚掉水里笑哭苏有朋！[SEP]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZwuPOwXwSA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "實作可以一次回傳一個 mini-batch 的 DataLoader\n",
        "這個 DataLoader 吃我們上面定義的 `FakeNewsDataset`，\n",
        "回傳訓練 BERT 時會需要的 4 個 tensors：\n",
        "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
        "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
        "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
        "- label_ids       : (batch_size)\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
        "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
        "# - tokens_tensor\n",
        "# - segments_tensor\n",
        "# - label_tensor\n",
        "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
        "def create_mini_batch(samples):\n",
        "    tokens_tensors = [s[0] for s in samples]\n",
        "    segments_tensors = [s[1] for s in samples]\n",
        "    \n",
        "    # 測試集有 labels\n",
        "    if samples[0][2] is not None:\n",
        "        label_ids = torch.stack([s[2] for s in samples])\n",
        "    else:\n",
        "        label_ids = None\n",
        "    \n",
        "    # zero pad 到同一序列長度\n",
        "    tokens_tensors = pad_sequence(tokens_tensors, \n",
        "                                  batch_first=True)\n",
        "    segments_tensors = pad_sequence(segments_tensors, \n",
        "                                    batch_first=True)\n",
        "    \n",
        "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
        "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
        "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
        "                                dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(\n",
        "        tokens_tensors != 0, 1)\n",
        "    \n",
        "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
        "\n",
        "\n",
        "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
        "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
        "BATCH_SIZE = 64\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
        "                         collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xoXMz1TwYYR",
        "colab_type": "code",
        "outputId": "f80363a6-e761-471d-879e-771bd69db4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "data = next(iter(trainloader))\n",
        "\n",
        "tokens_tensors, segments_tensors, \\\n",
        "    masks_tensors, label_ids = data\n",
        "\n",
        "print(f\"\"\"\n",
        "tokens_tensors.shape   = {tokens_tensors.shape} \n",
        "{tokens_tensors}\n",
        "------------------------\n",
        "segments_tensors.shape = {segments_tensors.shape}\n",
        "{segments_tensors}\n",
        "------------------------\n",
        "masks_tensors.shape    = {masks_tensors.shape}\n",
        "{masks_tensors}\n",
        "------------------------\n",
        "label_ids.shape        = {label_ids.shape}\n",
        "{label_ids}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens_tensors.shape   = torch.Size([64, 63]) \n",
            "tensor([[ 101, 5722, 3300,  ...,    0,    0,    0],\n",
            "        [ 101, 4255, 3160,  ..., 8013,  102,    0],\n",
            "        [ 101,  711, 2506,  ..., 8013,  102,    0],\n",
            "        ...,\n",
            "        [ 101,  671, 2157,  ...,    0,    0,    0],\n",
            "        [ 101, 1380,  677,  ...,    0,    0,    0],\n",
            "        [ 101, 2458, 1853,  ...,    0,    0,    0]])\n",
            "------------------------\n",
            "segments_tensors.shape = torch.Size([64, 63])\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 1, 0],\n",
            "        [0, 0, 0,  ..., 1, 1, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "------------------------\n",
            "masks_tensors.shape    = torch.Size([64, 63])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "------------------------\n",
            "label_ids.shape        = torch.Size([64])\n",
            "tensor([2, 0, 2, 2, 1, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
            "        2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0,\n",
            "        0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoMTGSljwZba",
        "colab_type": "code",
        "outputId": "196ccc2f-5b1f-4dec-cf7d-b297b6c18397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "048bb8e8da044654a6efbf3f83f1ada9",
            "c9970995733c4c36a55f4d090e31d393",
            "b38436bf09a64ad980baa81791fcd70a",
            "b7e36d7b23b84ca0b8a8f8df165b9d1e",
            "fbe665a6b889456db5abe8971557cfac",
            "87d9626c496d4fbea05e008707af8cfb",
            "1024a366fca6423f890741c7bd26c612",
            "77b411bb8eaa4f12bf541df95aa7907a",
            "c5021e91405048beb2a13a876efadcd2",
            "4ea8d6ca307b4657b8c47ad40fa4e58b",
            "032c493f46224096b9156e4e6999a5ed",
            "00736e59566d43078d56f168295fc9b7",
            "717091da54264b7b9487528926aaa74c",
            "ef8ff1a7f6bc4237928917f23eb82016",
            "91da11e9280047c6b6730150d046479a",
            "68cad836cae24f6fa66fe5c4b684b4b6"
          ]
        }
      },
      "source": [
        "# 載入一個可以做中文多分類任務的模型，n_class = 3\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "NUM_LABELS = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# high-level 顯示此模型裡的 modules\n",
        "print(\"\"\"\n",
        "name            module\n",
        "----------------------\"\"\")\n",
        "for name, module in model.named_children():\n",
        "    if name == \"bert\":\n",
        "        for n, _ in module.named_children():\n",
        "            print(f\"{name}:{n}\")\n",
        "    else:\n",
        "        print(\"{:15} {}\".format(name, module))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "name            module\n",
            "----------------------\n",
            "bert:embeddings\n",
            "bert:encoder\n",
            "bert:pooler\n",
            "dropout         Dropout(p=0.1, inplace=False)\n",
            "classifier      Linear(in_features=768, out_features=3, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa3kDjRMwkCy",
        "colab_type": "code",
        "outputId": "e8b7b8f0-9c95-451c-c1b6-842a719d9394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def get_predictions(model, dataloader, compute_acc=False):\n",
        "    predictions = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "      \n",
        "    with torch.no_grad():\n",
        "        # 遍巡整個資料集\n",
        "        for data in dataloader:\n",
        "            # 將所有 tensors 移到 GPU 上\n",
        "            if next(model.parameters()).is_cuda:\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "            \n",
        "            \n",
        "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
        "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
        "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
        "            outputs = model(input_ids=tokens_tensors, \n",
        "                            token_type_ids=segments_tensors, \n",
        "                            attention_mask=masks_tensors)\n",
        "            \n",
        "            logits = outputs[0]\n",
        "            _, pred = torch.max(logits.data, 1)\n",
        "            \n",
        "            # 用來計算訓練集的分類準確率\n",
        "            if compute_acc:\n",
        "                labels = data[3]\n",
        "                total += labels.size(0)\n",
        "                correct += (pred == labels).sum().item()\n",
        "                \n",
        "            # 將當前 batch 記錄下來\n",
        "            if predictions is None:\n",
        "                predictions = pred\n",
        "            else:\n",
        "                predictions = torch.cat((predictions, pred))\n",
        "    \n",
        "    if compute_acc:\n",
        "        acc = correct / total\n",
        "        return predictions, acc\n",
        "    return predictions\n",
        "    \n",
        "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "print(\"classification acc:\", acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "classification acc: 0.5385773428678962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HQalx7nxi7c",
        "colab_type": "code",
        "outputId": "0804b834-8e5a-4a57-b7a6-a03256eec5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "def get_learnable_params(module):\n",
        "    return [p for p in module.parameters() if p.requires_grad]\n",
        "     \n",
        "model_params = get_learnable_params(model)\n",
        "clf_params = get_learnable_params(model.classifier)\n",
        "\n",
        "print(f\"\"\"\n",
        "整個分類模型的參數量：{sum(p.numel() for p in model_params)}\n",
        "線性分類器的參數量：{sum(p.numel() for p in clf_params)}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "整個分類模型的參數量：102269955\n",
            "線性分類器的參數量：2307\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbjLm_JExnyr",
        "colab_type": "code",
        "outputId": "0821afc3-6e58-46e1-c936-d03b08f95bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# 訓練模式\n",
        "model.train()\n",
        "\n",
        "# 使用 Adam Optim 更新整個分類模型的參數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "\n",
        "EPOCHS = 6  # 幸運數字\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "\n",
        "        # 將參數梯度歸零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # 紀錄當前 batch loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # 計算分類準確率\n",
        "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "\n",
        "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
        "          (epoch + 1, running_loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1] loss: 27.556, acc: 0.812\n",
            "[epoch 2] loss: 18.563, acc: 0.865\n",
            "[epoch 3] loss: 13.896, acc: 0.886\n",
            "[epoch 4] loss: 10.188, acc: 0.939\n",
            "[epoch 5] loss: 7.675, acc: 0.935\n",
            "[epoch 6] loss: 7.819, acc: 0.977\n",
            "CPU times: user 2min 49s, sys: 1min 26s, total: 4min 16s\n",
            "Wall time: 4min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdIwBOKSydJ1",
        "colab_type": "code",
        "outputId": "dd226d35-d81c-4402-fd61-db641470c6b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# 建立測試集。這邊我們可以用跟訓練時不同的 batch_size，看你 GPU 多大\n",
        "testset = FakeNewsDataset(\"test\", tokenizer=tokenizer)\n",
        "testloader = DataLoader(testset, batch_size=256, \n",
        "                        collate_fn=create_mini_batch)\n",
        "\n",
        "# 用分類模型預測測試集\n",
        "predictions = get_predictions(model, testloader)\n",
        "\n",
        "# 用來將預測的 label id 轉回 label 文字\n",
        "index_map = {v: k for k, v in testset.label_map.items()}\n",
        "\n",
        "# 生成 Kaggle 繳交檔案\n",
        "df = pd.DataFrame({\"Category\": predictions.tolist()})\n",
        "df['Category'] = df.Category.apply(lambda x: index_map[x])\n",
        "df_pred = pd.concat([testset.df.loc[:, [\"Id\"]], \n",
        "                          df.loc[:, 'Category']], axis=1)\n",
        "df_pred.to_csv('/content/drive/My Drive/colab/bert/dataset/bert_1_prec_training_samples.csv', index=False)\n",
        "df_pred.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 24s, sys: 2min 7s, total: 6min 32s\n",
            "Wall time: 6min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg5Kbt6Q22_v",
        "colab_type": "code",
        "outputId": "50e80a0e-e89d-4a0c-9abb-34006c6f9607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls /content/drive/My Drive/colab/bert/dataset/bert*.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My': No such file or directory\n",
            "ls: cannot access 'Drive/colab/bert/dataset/bert*.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}