{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "suicide_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "289ce6c79ed44150af611024e9ce27ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73ca912a9f82402abbfa00af4b2097cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ba4699264e24f8ebe4fa5d8de8aa6fd",
              "IPY_MODEL_794687f874ed4c4d92d36f864c80ea6d"
            ]
          }
        },
        "73ca912a9f82402abbfa00af4b2097cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ba4699264e24f8ebe4fa5d8de8aa6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_706a9be548884ecea563d7f78320d696",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a9386e90051411091d00cac05eed98f"
          }
        },
        "794687f874ed4c4d92d36f864c80ea6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7be4afbf5cb64ebca2bd91a6fabc48a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:08&lt;00:00, 71.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18dfa471030f430ea598914a6ae1a1f4"
          }
        },
        "706a9be548884ecea563d7f78320d696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a9386e90051411091d00cac05eed98f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7be4afbf5cb64ebca2bd91a6fabc48a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18dfa471030f430ea598914a6ae1a1f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8f082f280ca4fbf933c9deebae651bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ca3b878cf6645b4ab5cc24baa156cdd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_552d3fc4d07f4a37b8adfa49c51213ac",
              "IPY_MODEL_5afb1465e6f14a99a1aff9ca2fa5467a"
            ]
          }
        },
        "6ca3b878cf6645b4ab5cc24baa156cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "552d3fc4d07f4a37b8adfa49c51213ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d12a47949fe4c5db9fab84efad10645",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c3611a36b8c42a7b0eb2921fdead6ad"
          }
        },
        "5afb1465e6f14a99a1aff9ca2fa5467a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14b897cfe3da4660b62a48e0642fc220",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:08&lt;00:00, 51.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bde83e8a708c424d9ce54a537515b9d9"
          }
        },
        "8d12a47949fe4c5db9fab84efad10645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c3611a36b8c42a7b0eb2921fdead6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14b897cfe3da4660b62a48e0642fc220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bde83e8a708c424d9ce54a537515b9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0d6KaszIB5P",
        "colab_type": "code",
        "outputId": "46cbbb76-0e6e-42db-b09a-42652748f71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNdV7B44MJEG",
        "colab_type": "code",
        "outputId": "56a90d09-8587-4cdd-fa6f-3bd6d7bf458d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install transformers\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhx-OxWeR-s_",
        "colab_type": "code",
        "outputId": "ece9a3c2-e430-4d1e-883e-12025262ba59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n",
        "\n",
        "# 取得此預訓練模型所使用的 tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "\n",
        "clear_output()\n",
        "print(\"PyTorch 版本：\", torch.__version__)\n",
        "\n",
        "vocab = tokenizer.vocab\n",
        "print(\"字典大小：\", len(vocab))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 版本： 1.5.0+cu101\n",
            "字典大小： 21128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNy3DZK6JPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\n",
        "pos_train_filename = \"/content/drive/My Drive/colab/bert/suicdie_dataset/normal.txt\"\n",
        "neg_train_filename = \"/content/drive/My Drive/colab/bert/suicdie_dataset/die.txt\"\n",
        "\n",
        "pos_test_filename=\"/content/drive/My Drive/colab/bert/suicdie_dataset/normal_test.txt\"\n",
        "neg_test_filename=\"/content/drive/My Drive/colab/bert/suicdie_dataset/die_test.txt\"\n",
        "\n",
        "col_name=['content']\n",
        "\n",
        "\n",
        "class SuicideDataset(Dataset):\n",
        "    \n",
        "  def __init__(self, mode, tokenizer):\n",
        "\n",
        "    assert mode in [\"train\", \"test\"]  \n",
        "    self.mode = mode\n",
        "    \n",
        "    if mode ==\"train\":\n",
        "\n",
        "      pos_train_df = pd.read_table(pos_train_filename,names=col_name).sample(50)\n",
        "      neg_train_df = pd.read_table(neg_train_filename,names=col_name).sample(50)\n",
        "  \n",
        "      pos_train_df['label'] = 0\n",
        "      neg_train_df['label'] = 1\n",
        "\n",
        "      self.train_df = pd.concat([pos_train_df,neg_train_df], axis=0, ignore_index=True)\n",
        "      self.train_df = self.train_df.sample(len(self.train_df))\n",
        "      self.len = len(self.train_df)\n",
        "    else:\n",
        "      pos_test_df = pd.read_table(pos_test_filename,names=col_name)\n",
        "      neg_test_df = pd.read_table(neg_test_filename,names=col_name)\n",
        "      self.test_df = pd.concat([pos_test_df,neg_test_df], axis=0, ignore_index=True)\n",
        "      self.test_df = self.test_df.sample(len(self.test_df))\n",
        "      self.len = len(self.test_df)\n",
        "      self.p_len=len(pos_test_df)\n",
        "      self.n_len=len(neg_test_df)\n",
        "\n",
        "    self.tokenizer = tokenizer  \n",
        "    \n",
        "  #@pysnooper.snoop()\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    if self.mode == \"test\":\n",
        "      text= self.test_df.iloc[idx, :].values\n",
        "      label_tensor = None\n",
        "    else:\n",
        "      text,label = self.train_df.iloc[idx, :].values\n",
        "      \n",
        "      label_id = label\n",
        "      label_tensor = torch.tensor(label_id).float()\n",
        "            \n",
        "    text=str(text)\n",
        "    word_pieces = [\"[CLS]\"]\n",
        "    tokens = self.tokenizer.tokenize(text)\n",
        "    word_pieces += tokens + [\"[SEP]\"]\n",
        "    len_t= len(word_pieces)\n",
        "        \n",
        "    \n",
        "    \n",
        "    ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "    tokens_tensor = torch.tensor(ids).float()\n",
        "    \n",
        "    \n",
        "    segments_tensor = torch.tensor([0] * len_t).float()\n",
        "                                        \n",
        "        \n",
        "    return (tokens_tensor, segments_tensor, label_tensor) #要特別注意這三個參數的資料型態\n",
        "    \n",
        "  def __len__(self):\n",
        "      return self.len\n",
        "\n",
        "#設定訓練與測試的資料集    \n",
        "\n",
        "trainset = SuicideDataset(\"train\", tokenizer=tokenizer)\n",
        "testset = SuicideDataset(\"test\", tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyA-jR8iEq5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "ddac593b-bf48-4b61-a969-ee7863d0ef49"
      },
      "source": [
        "# 選擇第一個樣本\n",
        "sample_idx = 0\n",
        "\n",
        "# 將原始文本拿出做比較\n",
        "text,label = trainset.train_df.iloc[sample_idx].values\n",
        "\n",
        "#print(testset.test_df)\n",
        "\n",
        "#testset.test_df.apply(toStr)\n",
        "tokens_tensor, segments_tensor, label_tensor = testset[sample_idx]\n",
        "\n",
        "#print(tokens_tensor)\n",
        "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
        "\n",
        "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
        "\n",
        "#print(type(tokens_tensor[0].item()))\n",
        "#print(type(segments_tensor[0].item()))\n",
        "#print(type(label_tensor.item()))\n",
        "\n",
        "print(tokens_tensor.type())\n",
        "print(segments_tensor.type())\n",
        "print(label_tensor.type())\n",
        "# 將 tokens_tensor 還原成文本\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
        "combined_text = \"\".join(tokens)\n",
        "\n",
        "# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
        "print(f\"\"\"[原始文本]\n",
        "句子 1：{text}\n",
        "\n",
        "分類  ：{label}\n",
        "\n",
        "--------------------\n",
        "\n",
        "[Dataset 回傳的 tensors]\n",
        "tokens_tensor  ：{tokens_tensor}\n",
        "\n",
        "segments_tensor：{segments_tensor}\n",
        "\n",
        "label_tensor   ：{label_tensor}\n",
        "\n",
        "--------------------\n",
        "\n",
        "[還原 tokens_tensors]\n",
        "{combined_text}\n",
        "\"\"\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "[原始文本]\n",
            "句子 1：#天天向上# 【今晚十点见】#周五不下班# 今天大舅妈换衣服了吗？[doge].................................换了！！！[憧憬][憧憬][憧憬]@王鸥Angel \n",
            "\n",
            "分類  ：0\n",
            "\n",
            "--------------------\n",
            "\n",
            "[Dataset 回傳的 tensors]\n",
            "tokens_tensor  ：tensor([  101.,   108.,  1921.,  1921.,  1403.,   677.,   108.,   523.,   791.,\n",
            "         3241.,  1282.,  4157.,  6224.,   524.,   108.,  1453.,   758.,   679.,\n",
            "          678.,  4408.,   108.,   791.,  1921.,  1920.,  5643.,  1968.,  2940.,\n",
            "         6132.,  3302.,   749.,  1408.,  8043.,   138., 13030.,  8154.,   140.,\n",
            "          119.,   119.,   119.,   119.,   119.,   119.,   119.,   119.,   119.,\n",
            "          119.,   119.,   119.,   119.,   119.,   119.,   119.,   119.,   119.,\n",
            "          119.,   119.,   119.,   119.,   119.,   119.,   119.,   119.,   119.,\n",
            "          119.,   119.,   119.,   119.,   119.,   119.,  2940.,   749.,  8013.,\n",
            "         8013.,  8013.,   138.,  2735.,  2739.,   140.,   138.,  2735.,  2739.,\n",
            "          140.,   138.,  2735.,  2739.,   140.,   137.,  4374.,  7886.,   100.,\n",
            "          102.])\n",
            "\n",
            "segments_tensor：tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "\n",
            "label_tensor   ：0.0\n",
            "\n",
            "--------------------\n",
            "\n",
            "[還原 tokens_tensors]\n",
            "[CLS]#天天向上#【今晚十点见】#周五不下班#今天大舅妈换衣服了吗？[dog##e].................................换了！！！[憧憬][憧憬][憧憬]@王鸥[UNK][SEP]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHaslGL4JQWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def create_mini_batch(samples):\n",
        "\n",
        "  samples_m=[]\n",
        "  for i,s in enumerate(samples):\n",
        "    #print(i,\"-->\",len(s[0]))\n",
        "    if len(s[0])<300: #過濾掉分詞之後字數超過300的資料，就bert目前其實也只接受最多512個字數\n",
        "      samples_m.append(s)\n",
        "\n",
        "  tokens_tensors = [s[0] for s in samples_m]\n",
        "  segments_tensors = [s[1] for s in samples_m]\n",
        "    \n",
        "  # 訓練集有 labels\n",
        "  if samples[0][2] is not None:\n",
        "      label_ids = torch.stack([s[2] for s in samples_m])\n",
        "  else:\n",
        "      label_ids = None\n",
        "    \n",
        "  # zero pad 到同一序列長度\n",
        "  tokens_tensors = pad_sequence(tokens_tensors, \n",
        "                                  batch_first=True)\n",
        "  segments_tensors = pad_sequence(segments_tensors, \n",
        "                                    batch_first=True)\n",
        "    \n",
        "  # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
        "  # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
        "  masks_tensors = torch.zeros(tokens_tensors.shape)\n",
        "                                \n",
        "  masks_tensors = masks_tensors.masked_fill(\n",
        "      tokens_tensors != 0, 1).float()\n",
        "    \n",
        "  return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
        "\n",
        "\n",
        "# 初始化一個每次回傳 16 個訓練樣本的 DataLoader\n",
        "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
        "BATCH_SIZE = 16\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
        "                         collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSEgpKVcJiG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "be02d4e2-57e3-410d-9663-f37d036a8be5"
      },
      "source": [
        "data = next(iter(trainloader))\n",
        "\n",
        "tokens_tensors, segments_tensors, \\\n",
        "    masks_tensors, label_ids = data\n",
        "print(len(data[0][0]))\n",
        "print(f\"\"\"\n",
        "tokens_tensors.shape   = {tokens_tensors.shape} \n",
        "{tokens_tensors}\n",
        "------------------------\n",
        "segments_tensors.shape = {segments_tensors.shape}\n",
        "{segments_tensors}\n",
        "------------------------\n",
        "masks_tensors.shape    = {masks_tensors.shape}\n",
        "{masks_tensors}\n",
        "------------------------\n",
        "label_ids.shape        = {label_ids.shape}\n",
        "{label_ids}\n",
        "\"\"\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "230\n",
            "\n",
            "tokens_tensors.shape   = torch.Size([16, 230]) \n",
            "tensor([[ 101.,  108., 1921.,  ...,    0.,    0.,    0.],\n",
            "        [ 101., 2769., 3297.,  ...,    0.,    0.,    0.],\n",
            "        [ 101., 2207., 4432.,  ...,    0.,    0.,    0.],\n",
            "        ...,\n",
            "        [ 101., 3209., 3209.,  ...,    0.,    0.,    0.],\n",
            "        [ 101., 2769., 6444.,  ...,    0.,    0.,    0.],\n",
            "        [ 101.,  100., 4376.,  ...,    0.,    0.,    0.]])\n",
            "------------------------\n",
            "segments_tensors.shape = torch.Size([16, 230])\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "------------------------\n",
            "masks_tensors.shape    = torch.Size([16, 230])\n",
            "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.]])\n",
            "------------------------\n",
            "label_ids.shape        = torch.Size([16])\n",
            "tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8pVdo-OKS4w",
        "colab_type": "code",
        "outputId": "917790b5-1bca-456e-cf62-045179bc3aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "289ce6c79ed44150af611024e9ce27ca",
            "73ca912a9f82402abbfa00af4b2097cc",
            "0ba4699264e24f8ebe4fa5d8de8aa6fd",
            "794687f874ed4c4d92d36f864c80ea6d",
            "706a9be548884ecea563d7f78320d696",
            "7a9386e90051411091d00cac05eed98f",
            "7be4afbf5cb64ebca2bd91a6fabc48a3",
            "18dfa471030f430ea598914a6ae1a1f4",
            "c8f082f280ca4fbf933c9deebae651bb",
            "6ca3b878cf6645b4ab5cc24baa156cdd",
            "552d3fc4d07f4a37b8adfa49c51213ac",
            "5afb1465e6f14a99a1aff9ca2fa5467a",
            "8d12a47949fe4c5db9fab84efad10645",
            "3c3611a36b8c42a7b0eb2921fdead6ad",
            "14b897cfe3da4660b62a48e0642fc220",
            "bde83e8a708c424d9ce54a537515b9d9"
          ]
        }
      },
      "source": [
        "# 以一維的數值作為output\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "NUM_LABELS = 1\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL_NAME,num_labels=NUM_LABELS)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# high-level 顯示此模型裡的 modules\n",
        "print(\"\"\"\n",
        "name            module\n",
        "----------------------\"\"\")\n",
        "for name, module in model.named_children():\n",
        "    if name == \"bert\":\n",
        "        for n, _ in module.named_children():\n",
        "            print(f\"{name}:{n}\")\n",
        "    else:\n",
        "        print(\"{:15} {}\".format(name, module))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "name            module\n",
            "----------------------\n",
            "bert:embeddings\n",
            "bert:encoder\n",
            "bert:pooler\n",
            "dropout         Dropout(p=0.1, inplace=False)\n",
            "classifier      Linear(in_features=768, out_features=1, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOHx3hTF4ZWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config={}\n",
        "\n",
        "model.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUYjFbgiLSPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def get_predictions(model, dataloader, compute_acc=False):\n",
        "\n",
        "\n",
        "  #predictions = None\n",
        "  predictions=[]\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  sum_len=0\n",
        "  dataset_num=len(dataloader.dataset)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "  #print(len(dataloader))\n",
        "    for data in dataloader:\n",
        "      #if next(model.parameters()).is_cuda:\n",
        "      #print(len(dataloader))\n",
        "      #data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "      #print(len(dataloader.dataset))\n",
        "\n",
        "      if next(model.parameters()).is_cuda:\n",
        "        data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "        \n",
        "      tokens_tensors, segments_tensors, masks_tensors=data[:3]\n",
        "\n",
        "      #print(len(tokens_tensors))\n",
        "      sum_len+=len(tokens_tensors)\n",
        "      #print((sum_len/dataset_num)*100,'%')\n",
        "      #print(len(segments_tensors[0]))\n",
        "      #print(len(masks_tensors[0]))\n",
        "      #print(len(data))\n",
        "\n",
        "      outputs = model(input_ids=tokens_tensors.long(), \n",
        "                      token_type_ids=segments_tensors.long(), \n",
        "                      attention_mask=masks_tensors.long(),\n",
        "                      \n",
        "                      )\n",
        "            \n",
        "      logits = outputs[0]\n",
        "      \n",
        "      pred=logits.data\n",
        "\n",
        "      pred_s = torch.sigmoid(pred)\n",
        "      print(pred_s)\n",
        "\n",
        "      for p in range(0,len(pred_s)):\n",
        "        if pred_s[p]>0.7: #將輸出超過0.7的數值將其設為標籤\"1\"其餘為\"0\"\n",
        "          pred_s[p]=1\n",
        "        else:\n",
        "          pred_s[p]=0\n",
        "      \n",
        "      print(pred_s)\n",
        "\n",
        "      z=0\n",
        "      o=0\n",
        "      for s in pred_s:\n",
        "        if(s==0.0):\n",
        "          z=z+1\n",
        "        else:\n",
        "          o=o+1\n",
        "\n",
        "      print(\"z:\",z,\"o:\",o)\n",
        "      pred_s=torch.squeeze(pred_s)\n",
        "      \n",
        "      \n",
        "      if compute_acc:\n",
        "        labels = data[3]\n",
        "        total += labels.size(0)\n",
        "        correct += (pred_s == labels).sum().item()\n",
        "     \n",
        "   \n",
        "    if compute_acc:#算出精準度\n",
        "      #print(total)\n",
        "      acc = correct / total\n",
        "      return predictions, acc\n",
        "    return predictions\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nT6CSTJhpYM",
        "colab_type": "code",
        "outputId": "2cf48890-5376-4fd1-cd10-faee3dae72c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx3bLhx9kohd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, acc = get_predictions(model, trainloader, compute_acc=True) \n",
        "print(\"classification acc:\", acc) #測試是否可以預測"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GyMbPVmefbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練模式\n",
        "model.train()\n",
        "\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "# 使用 Adam Optim 更新整個分類模型的參數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4) #, lr=1.0e-4\n",
        "#optimizer = AdamW(model.parameters(), lr=1e-3, correct_bias=False)\n",
        "#sum_t=0\n",
        "\n",
        "EPOCHS = 6  # 幸運數字\n",
        "for epoch in range(EPOCHS):\n",
        "    sum_t=0\n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        \n",
        "        #sum_t+=str(len(tokens_tensors)\n",
        "\n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "\n",
        "        sum_t+=len(tokens_tensors)\n",
        "\n",
        "        #print(type(labels[0].item()))\n",
        "        print(\"epoch:\"+str(epoch)+\",\"+str((sum_t)/len(trainloader.dataset)*100)+\"%\")\n",
        "        # 將參數梯度歸零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids=tokens_tensors.long(), \n",
        "                        token_type_ids=segments_tensors.long(), \n",
        "                        attention_mask=masks_tensors.long(), \n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        #print(loss)\n",
        "        #print(outputs[1].type())\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # 紀錄當前 batch loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # 計算分類準確率\n",
        "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "\n",
        "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
        "          (epoch + 1, running_loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy7ziWPcytx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = SuicideDataset(\"test\", tokenizer=tokenizer)\n",
        "testloader = DataLoader(testset, batch_size=300, \n",
        "                        collate_fn=create_mini_batch)\n",
        "\n",
        "sample_idx=0\n",
        "text= testset.test_df.iloc[sample_idx].values\n",
        "#print(text)\n",
        "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
        "print(testset.p_len)\n",
        "print(testset.n_len)\n",
        "#print(text)\n",
        "#tokens = tokenizer.tokenize(text)\n",
        "#testset[sample_idx]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPfK2ISO_SA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = get_predictions(model, testloader)\n",
        "\n",
        "#利用訓練好的模型進行預測測試資料集\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}